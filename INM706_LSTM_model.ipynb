{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03987db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is developed from the unfinished code for 2023 submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cf83031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/miniconda3/lib/python3.12/site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/miniconda3/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/charlesciumei/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn\n",
    "\n",
    "import os,sys,re\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "nltk.download('punkt')   # from nltk documentation in case it is not already downloaded\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a35f182b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# Device configuration. Use Apple Silicon or AMD GPU if available\n",
    "# from https://developer.apple.com/metal/pytorch/\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f1b71f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This builds a vocabulary. Text preprocessing handled in dataset class below \n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self, filepath, show_vocab=False):\n",
    "        self.filepath = filepath\n",
    "        self.word_to_idx = {\"<PAD>\": 0, \"<UNK>\": 1} # Reserve 0 and 1 indices for padding and unknown tokens\n",
    "        self.idx_to_word = {0: \"<PAD>\", 1: \"<UNK>\"}\n",
    "        self.show_vocab = show_vocab # boolean to print vocab for testing\n",
    "        self._build_vocab()\n",
    "        \n",
    "    def _build_vocab(self):\n",
    "        with open(self.filepath, 'r') as f:\n",
    "            text = f.read().split()\n",
    "\n",
    "        # Build the vocabulary, use sorted to ensure the same order\n",
    "        unique_words = sorted(set(text))\n",
    "        # print(unique_words) # used to test vocab contents\n",
    "        for word in unique_words:\n",
    "            if word not in self.word_to_idx:\n",
    "                idx = len(self.word_to_idx)\n",
    "                self.word_to_idx[word] = idx\n",
    "                self.idx_to_word[idx] = word\n",
    "        print('Vocabulary size: ', len(self.word_to_idx))\n",
    "        if self.show_vocab:\n",
    "            print(self.tokenised_list)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        # Split the text into words and convert to indices\n",
    "        return [self.word_to_idx.get(word, self.word_to_idx[\"<UNK>\"]) for word in text.split()]\n",
    "\n",
    "    def detokenize(self, indices):\n",
    "        # Convert indices to words and join them into a text\n",
    "        return \" \".join(self.idx_to_word.get(ix, \"<UNK>\") for ix in indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.word_to_idx)\n",
    "\n",
    "# This loads and creates the dataset for training and testing and builds the vocabulary using Vocab class\n",
    "# Code and use of nltk toolkit from 2023 Lab3 code and nltk documentation\n",
    "# Dataset class use from Pytorch examples\n",
    "\n",
    "class Textdataset(Dataset):\n",
    "    def __init__(self, filepath, max_sequence_length=25, show_vocab=False):\n",
    "        # self.start_token = \"<BOS>\"\n",
    "        # self.end_token = \"<EOS>\"\n",
    "        # self.text_tokenised = self._pre_process_text()\n",
    "        self.filepath = filepath\n",
    "        self.show_vocab = show_vocab\n",
    "        self.vocab = Vocab(filepath)\n",
    "        self.data = []\n",
    "        self.max_sequence_length = max_sequence_length \n",
    "        self.sequence_builder()\n",
    "\n",
    "    # Build the source and target sequences by iterating over tokenized text\n",
    "    # length-1 otherwise last sequence is too short\n",
    "    def sequence_builder(self):\n",
    "        with open (self.filepath, 'r', encoding=\"utf-8\") as f:\n",
    "            text = self.vocab.tokenize(f.read())\n",
    "        \n",
    "        # make the sequences\n",
    "        for i in range(len(text)-self.max_sequence_length-1): \n",
    "            source_sequence = text[i:i+self.max_sequence_length]\n",
    "            # target=source shifted by 1\n",
    "            target_sequence = text[i+1:i+self.max_sequence_length+1]\n",
    "            self.data.append((source_sequence, target_sequence)) \n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        # Pad the source sequences to the same length\n",
    "        source_sequences, target_sequences = zip(*batch)\n",
    "        source_sequences = pad_sequence(source_sequences, batch_first=True, padding_value=self.vocab.word_to_idx[\"<PAD>\"])\n",
    "        target_sequences = torch.stack(target_sequences, dim=0)\n",
    "        return source_sequences, target_sequences\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Return the item at the specified index\n",
    "        # Returns a source_sequence and a target sequence pair\n",
    "        source_sequence, target_sequence = self.data[idx]\n",
    "        source_sequence = torch.tensor(source_sequence, dtype=torch.long)\n",
    "        target_sequence = torch.tensor(target_sequence, dtype=torch.long)\n",
    "        return source_sequence, target_sequence\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a3e4dc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  1019\n"
     ]
    }
   ],
   "source": [
    "# Test to show that the code above works to create dataset and a vocab.\n",
    "# Uses print statement in Vocab class now commented out\n",
    "# The test data is the first chapter of the the novel\n",
    "\n",
    "dataset1 = Textdataset(\"dataset/Can_You_Forgive_Her_Ch1.txt\", show_vocab=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7522d10f-c3fd-486a-bc69-85d270181090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  85,   35,   17,   35,   59,   86,  140,   32,   23,   95,  697,  661,\n",
       "          825,  979, 1014,  153,  921,  427,  522, 1014,  226,  313,  697,  313,\n",
       "          669]),\n",
       " tensor([  35,   17,   35,   59,   86,  140,   32,   23,   95,  697,  661,  825,\n",
       "          979, 1014,  153,  921,  427,  522, 1014,  226,  313,  697,  313,  669,\n",
       "          192]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ddeb1507-ae3a-4ed3-8ff6-d8bd47b097f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model\n",
    "\n",
    "class LSTMmodel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, n_layers):\n",
    "        super(LSTMmodel, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden = self.init_hidden(x.size(0))\n",
    "        # Get word embeddings\n",
    "        embedding_out = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embedding_out, hidden)\n",
    "        # Get predictions\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.fc(lstm_out)\n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # Initialize hidden state with zero weights, and move to GPU if available\n",
    "        weight = next(self.parameters()).data\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6899e7d4-cba3-4ee2-90ca-0ff2dabf11c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger:\n",
    "    # define a logger for Wandb - taken from Lab 4 2024\n",
    "    def __init__(self, project='CC_INM706_1'):\n",
    "        logger = wandb.init(project=project)\n",
    "        self.logger = logger\n",
    "        return\n",
    "\n",
    "    def get_logger(self):\n",
    "        return self.logger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "822b8228-e0d9-4b9e-8bf2-946d0021e7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train loop\n",
    "\n",
    "def train(model, train_dataset, eval_dataset, epochs, batch_size, learning_rate):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    eval_loader = DataLoader(eval_dataset, batch_size=batch_size)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    wandb_logger = Logger()\n",
    "    logger = wandb_logger.get_logger()\n",
    "\n",
    "    train_losses, train_perplexities, eval_losses, eval_perplexities = [], [], [], []\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        total_tokens = 0\n",
    "\n",
    "        model.train()\n",
    "        for inputs, targets in tqdm(train_loader, 'Training', leave=False):\n",
    "            # Move data to the proper device\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs, _ = model(inputs)\n",
    "            targets = targets.view(-1)  # Reshape targets\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Keep track of total loss and tokens\n",
    "            total_loss += loss.item() * targets.shape[0]\n",
    "            total_tokens += targets.shape[0]\n",
    "\n",
    "        train_loss = total_loss / total_tokens\n",
    "        train_perplexity = np.exp(train_loss)\n",
    "        train_losses.append(train_loss)\n",
    "        train_perplexities.append(train_perplexity)\n",
    "\n",
    "        # Evaluate after each epoch\n",
    "        eval_loss, eval_perplexity = evaluate(model, eval_loader)\n",
    "        eval_losses.append(eval_loss)\n",
    "        eval_perplexities.append(eval_perplexity)\n",
    "\n",
    "        print(f'Train Epoch {epoch+1}/{epochs}, Loss: {train_loss:.4f}, Perplexity: {train_perplexity:.2f}, Eval Loss: {eval_loss:.4f}, Eval Perplexity: {eval_perplexity:.2f}')\n",
    "\n",
    "        # set up custom wandb log for eval perplexity based on code in wandb documentation\n",
    "    \n",
    "        # Set up data to log eval perplexity at each epoch\n",
    "        if epoch == 0:\n",
    "            plot_data = [] # to prevent resetting data to zero on every loop\n",
    "        else:\n",
    "            plot_data.append([epoch, eval_perplexity])\n",
    "        \n",
    "        # Create a table with the columns to plot\n",
    "        table = wandb.Table(data=plot_data, columns=[\"epoch\", \"eval_p\"])\n",
    "\n",
    "        # Use the table to populate various custom charts\n",
    "        line_plot = wandb.plot.line(table, x='epoch', y='eval_p', title='Line Plot')\n",
    "  \n",
    "        # Log custom tables, which will show up in customizable charts in the UI\n",
    "        wandb.log({'line_1': line_plot,})\n",
    "\n",
    "        # set up custom wandb log for training loss perplexity based on code in wandb documentation\n",
    "    \n",
    "        # Set up data to log eval loss at each epoch\n",
    "        if epoch == 0:\n",
    "            loss_data = [] # to prevent resetting data to zero on every loop\n",
    "        else:\n",
    "            loss_data.append([epoch, train_loss])\n",
    "        \n",
    "        # Create a table with the columns to plot\n",
    "        loss_table = wandb.Table(data=loss_data, columns=[\"epoch\", \"loss\"])\n",
    "\n",
    "        # Use the table to populate various custom charts\n",
    "        loss_plot = wandb.plot.line(loss_table, x='epoch', y='loss', title='Line Plot')\n",
    "  \n",
    "        # Log custom tables, which will show up in customizable charts in the UI\n",
    "        wandb.log({'line_1': loss_plot,})\n",
    "\n",
    "\n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), 'LSTMmodel.pth')\n",
    "\n",
    "# evaluate model to calculate perplexity of generated text\n",
    "def evaluate(model, dataloader):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_tokens = 0\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for inputs, targets in tqdm(dataloader, desc='Evaluating', leave=False):\n",
    "            # Move data to the proper device\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs, _ = model(inputs)\n",
    "            targets = targets.view(-1)  # Reshape targets\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # Keep track of total loss and tokens\n",
    "            total_loss += loss.item() * targets.shape[0]\n",
    "            total_tokens += targets.shape[0]\n",
    "\n",
    "\n",
    "    eval_loss = total_loss / total_tokens\n",
    "    eval_perplexity = np.exp(eval_loss)\n",
    "    print(f'Eval Loss: {eval_loss:.4f}, Eval Perplexity: {eval_perplexity:.2f}')\n",
    "    return eval_loss, eval_perplexity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "19b74edb-314b-4c18-8aad-8c37bc5929f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  2845\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:gep2p9ha) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hearty-pine-10</strong> at: <a href='https://wandb.ai/ciumei/CC_INM706_1/runs/gep2p9ha' target=\"_blank\">https://wandb.ai/ciumei/CC_INM706_1/runs/gep2p9ha</a><br/> View project at: <a href='https://wandb.ai/ciumei/CC_INM706_1' target=\"_blank\">https://wandb.ai/ciumei/CC_INM706_1</a><br/>Synced 6 W&B file(s), 25 media file(s), 25 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240519_083350-gep2p9ha/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:gep2p9ha). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/charlesciumei/Dropbox/__python_playground/INM706/_2024_INM706/simpler model/wandb/run-20240519_124244-af9133lo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ciumei/CC_INM706_1/runs/af9133lo' target=\"_blank\">trim-smoke-11</a></strong> to <a href='https://wandb.ai/ciumei/CC_INM706_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ciumei/CC_INM706_1' target=\"_blank\">https://wandb.ai/ciumei/CC_INM706_1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ciumei/CC_INM706_1/runs/af9133lo' target=\"_blank\">https://wandb.ai/ciumei/CC_INM706_1/runs/af9133lo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 5.6268, Eval Perplexity: 277.77\n",
      "Train Epoch 1/25, Loss: 6.2966, Perplexity: 542.74, Eval Loss: 5.6268, Eval Perplexity: 277.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 4.3628, Eval Perplexity: 78.47\n",
      "Train Epoch 2/25, Loss: 4.9731, Perplexity: 144.47, Eval Loss: 4.3628, Eval Perplexity: 78.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 3.2038, Eval Perplexity: 24.63\n",
      "Train Epoch 3/25, Loss: 3.7423, Perplexity: 42.19, Eval Loss: 3.2038, Eval Perplexity: 24.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 2.2352, Eval Perplexity: 9.35\n",
      "Train Epoch 4/25, Loss: 2.6390, Perplexity: 14.00, Eval Loss: 2.2352, Eval Perplexity: 9.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 1.5114, Eval Perplexity: 4.53\n",
      "Train Epoch 5/25, Loss: 1.7728, Perplexity: 5.89, Eval Loss: 1.5114, Eval Perplexity: 4.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 1.0293, Eval Perplexity: 2.80\n",
      "Train Epoch 6/25, Loss: 1.1655, Perplexity: 3.21, Eval Loss: 1.0293, Eval Perplexity: 2.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.7277, Eval Perplexity: 2.07\n",
      "Train Epoch 7/25, Loss: 0.7737, Perplexity: 2.17, Eval Loss: 0.7277, Eval Perplexity: 2.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.5528, Eval Perplexity: 1.74\n",
      "Train Epoch 8/25, Loss: 0.5397, Perplexity: 1.72, Eval Loss: 0.5528, Eval Perplexity: 1.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.4628, Eval Perplexity: 1.59\n",
      "Train Epoch 9/25, Loss: 0.4068, Perplexity: 1.50, Eval Loss: 0.4628, Eval Perplexity: 1.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.4122, Eval Perplexity: 1.51\n",
      "Train Epoch 10/25, Loss: 0.3296, Perplexity: 1.39, Eval Loss: 0.4122, Eval Perplexity: 1.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.3808, Eval Perplexity: 1.46\n",
      "Train Epoch 11/25, Loss: 0.2823, Perplexity: 1.33, Eval Loss: 0.3808, Eval Perplexity: 1.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.3616, Eval Perplexity: 1.44\n",
      "Train Epoch 12/25, Loss: 0.2510, Perplexity: 1.29, Eval Loss: 0.3616, Eval Perplexity: 1.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.3512, Eval Perplexity: 1.42\n",
      "Train Epoch 13/25, Loss: 0.2297, Perplexity: 1.26, Eval Loss: 0.3512, Eval Perplexity: 1.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.3425, Eval Perplexity: 1.41\n",
      "Train Epoch 14/25, Loss: 0.2131, Perplexity: 1.24, Eval Loss: 0.3425, Eval Perplexity: 1.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.3380, Eval Perplexity: 1.40\n",
      "Train Epoch 15/25, Loss: 0.2006, Perplexity: 1.22, Eval Loss: 0.3380, Eval Perplexity: 1.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.3347, Eval Perplexity: 1.40\n",
      "Train Epoch 16/25, Loss: 0.1911, Perplexity: 1.21, Eval Loss: 0.3347, Eval Perplexity: 1.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.3341, Eval Perplexity: 1.40\n",
      "Train Epoch 17/25, Loss: 0.1831, Perplexity: 1.20, Eval Loss: 0.3341, Eval Perplexity: 1.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.3320, Eval Perplexity: 1.39\n",
      "Train Epoch 18/25, Loss: 0.1771, Perplexity: 1.19, Eval Loss: 0.3320, Eval Perplexity: 1.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.3318, Eval Perplexity: 1.39\n",
      "Train Epoch 19/25, Loss: 0.1722, Perplexity: 1.19, Eval Loss: 0.3318, Eval Perplexity: 1.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.3332, Eval Perplexity: 1.40\n",
      "Train Epoch 20/25, Loss: 0.1681, Perplexity: 1.18, Eval Loss: 0.3332, Eval Perplexity: 1.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.3333, Eval Perplexity: 1.40\n",
      "Train Epoch 21/25, Loss: 0.1647, Perplexity: 1.18, Eval Loss: 0.3333, Eval Perplexity: 1.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.3348, Eval Perplexity: 1.40\n",
      "Train Epoch 22/25, Loss: 0.1615, Perplexity: 1.18, Eval Loss: 0.3348, Eval Perplexity: 1.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.3382, Eval Perplexity: 1.40\n",
      "Train Epoch 23/25, Loss: 0.1589, Perplexity: 1.17, Eval Loss: 0.3382, Eval Perplexity: 1.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.3371, Eval Perplexity: 1.40\n",
      "Train Epoch 24/25, Loss: 0.1569, Perplexity: 1.17, Eval Loss: 0.3371, Eval Perplexity: 1.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.3367, Eval Perplexity: 1.40\n",
      "Train Epoch 25/25, Loss: 0.1550, Perplexity: 1.17, Eval Loss: 0.3367, Eval Perplexity: 1.40\n"
     ]
    }
   ],
   "source": [
    "# Running the model\n",
    "dataset = Textdataset('dataset/Can_You_Forgive_Her_Chs_1_3.txt', max_sequence_length=25)\n",
    "train_indices, eval_indices = train_test_split(list(range(len(dataset))), test_size=0.2, random_state=42)\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "eval_dataset = Subset(dataset, eval_indices)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "vocab_size = len(dataset.vocab.word_to_idx)\n",
    "embed_size = 128\n",
    "hidden_size = 256\n",
    "n_layers = 2\n",
    "\n",
    "model = LSTMmodel(vocab_size, embed_size, hidden_size, n_layers)  #.to(device)\n",
    "train(model, train_dataset, eval_dataset, epochs=25 , batch_size=32, learning_rate=0.001)\n",
    "\n",
    "# Not where to put code to end wandb logging. From wandb documentation for use in Jupyter notebooks.\n",
    "# run.finish()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
